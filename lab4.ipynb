{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec4a4ab3",
   "metadata": {},
   "source": [
    "# Lab 4\n",
    "# Extend ETL pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d8caf",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32f8509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589143a",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a11cd008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file: custom_data.csv\n"
     ]
    }
   ],
   "source": [
    "DATA_FILE = 'custom_data.csv' # Your existing data file\n",
    "LAST_EXTRACTION_FILE = 'last_extraction.txt'\n",
    "OUTPUT_FULL_TRANSFORMED_FILENAME = 'transformed_full.csv'\n",
    "OUTPUT_INCREMENTAL_TRANSFORMED_FILENAME = 'transformed_incremental.csv'\n",
    "print(f\"Data file: {DATA_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d3626f",
   "metadata": {},
   "source": [
    "#### Full extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eee310c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 338\n",
      "Number of columns: 10\n",
      "   record_id transaction_date transaction_timestamp customer_name  \\\n",
      "0          1       2025-04-01   2025-04-01T17:49:57        Costco   \n",
      "1          2       2025-04-01   2025-04-01T10:36:18         Apple   \n",
      "2          3       2025-04-01   2025-04-01T17:16:47        Target   \n",
      "3          4       2025-04-01   2025-04-01T18:15:48        Costco   \n",
      "4          5       2025-04-01   2025-04-01T02:37:35        Amazon   \n",
      "\n",
      "  product_category   amount  quantity payment_method last_updated_timestamp  \\\n",
      "0      Electronics   929.94         1         PayPal    2025-04-01T18:49:57   \n",
      "1        Groceries   130.17         4         PayPal    2025-04-01T12:59:18   \n",
      "2       Home Goods  1333.76         8    Credit Card    2025-04-01T18:19:47   \n",
      "3            Tools  1115.54         9         PayPal    2025-04-01T20:41:48   \n",
      "4         Software   633.14         6    Credit Card    2025-04-01T03:35:35   \n",
      "\n",
      "      status  \n",
      "0    Pending  \n",
      "1  Cancelled  \n",
      "2    Pending  \n",
      "3  Cancelled  \n",
      "4  Cancelled  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 338 entries, 0 to 337\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   record_id               338 non-null    int64  \n",
      " 1   transaction_date        338 non-null    object \n",
      " 2   transaction_timestamp   338 non-null    object \n",
      " 3   customer_name           338 non-null    object \n",
      " 4   product_category        338 non-null    object \n",
      " 5   amount                  338 non-null    float64\n",
      " 6   quantity                338 non-null    int64  \n",
      " 7   payment_method          338 non-null    object \n",
      " 8   last_updated_timestamp  338 non-null    object \n",
      " 9   status                  338 non-null    object \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 26.5+ KB\n",
      "None\n",
      "\n",
      "Extracted 338 rows fully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_full_extraction = pd.DataFrame() # Initialize an empty DataFrame\n",
    "\n",
    "try:\n",
    "    if os.path.exists(DATA_FILE):\n",
    "        df_full_extraction = pd.read_csv(DATA_FILE)\n",
    "        print(f\"Number of rows: {df_full_extraction.shape[0]}\")\n",
    "        print(f\"Number of columns: {df_full_extraction.shape[1]}\")\n",
    "        print(df_full_extraction.head())\n",
    "        print(df_full_extraction.info())\n",
    "\n",
    "        print(f\"\\nExtracted {df_full_extraction.shape[0]} rows fully.\")\n",
    "    else:\n",
    "        print(f\"Error: The file '{DATA_FILE}' was not found\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during full extraction: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec8dea7",
   "metadata": {},
   "source": [
    "### Incremental extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1374a487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last extraction timestamp: 2025-06-09 20:56:34.567175\n",
      "\n",
      "Extracted 0 rows incrementally since last check (2025-06-09 20:56:34.567175).\n",
      "No new or updated records found.\n"
     ]
    }
   ],
   "source": [
    "def get_last_extraction_timestamp(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            try:\n",
    "                timestamp_str = f.read().strip()\n",
    "                if timestamp_str:\n",
    "                    return datetime.fromisoformat(timestamp_str)\n",
    "                else:\n",
    "                    return datetime.min \n",
    "            except ValueError:\n",
    "                return datetime.min \n",
    "    else:\n",
    "        return datetime.min \n",
    "\n",
    "last_extraction_time = get_last_extraction_timestamp(LAST_EXTRACTION_FILE)\n",
    "print(f\"Last extraction timestamp: {last_extraction_time}\")\n",
    "\n",
    "df_incremental_extraction = pd.DataFrame() \n",
    "\n",
    "try:\n",
    "    if not df_full_extraction.empty: \n",
    "        df_full_extraction['last_updated_timestamp'] = pd.to_datetime(df_full_extraction['last_updated_timestamp'], errors='coerce')\n",
    "        df_current_data_valid_timestamps = df_full_extraction.dropna(subset=['last_updated_timestamp'])\n",
    "\n",
    "        df_incremental_extraction = df_current_data_valid_timestamps[\n",
    "            df_current_data_valid_timestamps['last_updated_timestamp'] > last_extraction_time\n",
    "        ].copy() \n",
    "\n",
    "        print(f\"\\nExtracted {df_incremental_extraction.shape[0]} rows incrementally since last check ({last_extraction_time}).\")\n",
    "\n",
    "        if not df_incremental_extraction.empty:\n",
    "            print(\"\\nIncremental data extracted (first 5 rows):\")\n",
    "            print(df_incremental_extraction.head())\n",
    "        else:\n",
    "            print(\"No new or updated records found.\")\n",
    "    else:\n",
    "        print(\"Full extraction DataFrame is empty, cannot perform incremental extraction.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during incremental extraction: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ca651",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c969135d",
   "metadata": {},
   "source": [
    "#### Full DAta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cf4946b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - No duplicate records found based on 'record_id'.\n",
      "    - Stripped whitespace from string columns.\n",
      "    - Standardized 'status' column casing.\n",
      "    - Handling missing values in critical columns...\n",
      "    - No rows dropped due to missing critical data after type conversion.\n",
      "  - Applying structural transformations (data type conversions)...\n",
      "  - Applying enrichment transformations...\n",
      "    - Calculating 'total_price'...\n",
      "  - Applying structural transformations (column selection and renaming)...\n",
      "\n",
      "Transformed 338 records from full extraction.\n",
      "\n",
      "First 5 rows of transformed full data:\n",
      "   transaction_id transaction_date transaction_timestamp customer  \\\n",
      "0               1       2025-04-01   2025-04-01 17:49:57   Costco   \n",
      "1               2       2025-04-01   2025-04-01 10:36:18    Apple   \n",
      "2               3       2025-04-01   2025-04-01 17:16:47   Target   \n",
      "3               4       2025-04-01   2025-04-01 18:15:48   Costco   \n",
      "4               5       2025-04-01   2025-04-01 02:37:35   Amazon   \n",
      "\n",
      "      category  quantity   amount  total_price payment_type     status  \n",
      "0  Electronics         1   929.94       929.94       PayPal    Pending  \n",
      "1    Groceries         4   130.17       520.68       PayPal  Cancelled  \n",
      "2   Home Goods         8  1333.76     10670.08  Credit Card    Pending  \n",
      "3        Tools         9  1115.54     10039.86       PayPal  Cancelled  \n",
      "4     Software         6   633.14      3798.84  Credit Card  Cancelled  \n",
      "\n",
      "Data types of transformed full data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 338 entries, 0 to 337\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   transaction_id         338 non-null    int64         \n",
      " 1   transaction_date       338 non-null    datetime64[ns]\n",
      " 2   transaction_timestamp  338 non-null    datetime64[ns]\n",
      " 3   customer               338 non-null    object        \n",
      " 4   category               338 non-null    object        \n",
      " 5   quantity               338 non-null    int64         \n",
      " 6   amount                 338 non-null    float64       \n",
      " 7   total_price            338 non-null    float64       \n",
      " 8   payment_type           338 non-null    object        \n",
      " 9   status                 338 non-null    object        \n",
      "dtypes: datetime64[ns](2), float64(2), int64(2), object(4)\n",
      "memory usage: 29.0+ KB\n",
      "None\n",
      "\n",
      "Transformed full data successfully saved to 'transformed_full.csv'\n"
     ]
    }
   ],
   "source": [
    "def transform_sales_data(df):\n",
    "    df_transformed = df.copy()\n",
    "    initial_rows = len(df_transformed)\n",
    "    df_transformed.drop_duplicates(subset=['record_id'], keep='first', inplace=True)\n",
    "    if len(df_transformed) < initial_rows:\n",
    "        print(f\"    - Removed {initial_rows - len(df_transformed)} duplicate records based on 'record_id'.\")\n",
    "    else:\n",
    "        print(\"    - No duplicate records found based on 'record_id'.\")\n",
    "\n",
    "    for col in ['customer_name', 'product_category', 'payment_method', 'status']:\n",
    "        if col in df_transformed.columns and df_transformed[col].dtype == 'object':\n",
    "            df_transformed[col] = df_transformed[col].str.strip()\n",
    "    print(\"    - Stripped whitespace from string columns.\")\n",
    "\n",
    "    if 'status' in df_transformed.columns:\n",
    "        df_transformed['status'] = df_transformed['status'].str.title()\n",
    "        print(\"    - Standardized 'status' column casing.\")\n",
    "\n",
    "    print(\"    - Handling missing values in critical columns...\")\n",
    "    original_rows_after_duplicates = len(df_transformed)\n",
    "    df_transformed.dropna(subset=['amount', 'quantity', 'transaction_date', 'transaction_timestamp'], inplace=True)\n",
    "    if len(df_transformed) < original_rows_after_duplicates:\n",
    "        print(f\"    - Dropped {original_rows_after_duplicates - len(df_transformed)} rows due to invalid data (e.g., missing amount, quantity, or timestamps).\")\n",
    "    else:\n",
    "        print(\"    - No rows dropped due to missing critical data after type conversion.\")\n",
    "\n",
    "\n",
    "    print(\"  - Applying structural transformations (data type conversions)...\")\n",
    "    df_transformed['transaction_date'] = pd.to_datetime(df_transformed['transaction_date'], errors='coerce')\n",
    "    df_transformed['transaction_timestamp'] = pd.to_datetime(df_transformed['transaction_timestamp'], errors='coerce')\n",
    "    df_transformed['last_updated_timestamp'] = pd.to_datetime(df_transformed['last_updated_timestamp'], errors='coerce')\n",
    "    df_transformed['amount'] = pd.to_numeric(df_transformed['amount'], errors='coerce')\n",
    "    df_transformed['quantity'] = pd.to_numeric(df_transformed['quantity'], errors='coerce')\n",
    "\n",
    "\n",
    "    print(\"  - Applying enrichment transformations...\")\n",
    "    print(\"    - Calculating 'total_price'...\")\n",
    "    df_transformed['total_price'] = df_transformed['quantity'] * df_transformed['amount']\n",
    "\n",
    "\n",
    "    print(\"  - Applying structural transformations (column selection and renaming)...\")\n",
    "    selected_columns = [\n",
    "        'record_id',\n",
    "        'transaction_date',\n",
    "        'transaction_timestamp',\n",
    "        'customer_name',\n",
    "        'product_category',\n",
    "        'quantity',\n",
    "        'amount',\n",
    "        'total_price',\n",
    "        'payment_method',\n",
    "        'status'\n",
    "    ]\n",
    "    df_transformed = df_transformed[[col for col in selected_columns if col in df_transformed.columns]]\n",
    "\n",
    "    df_transformed.rename(columns={\n",
    "        'record_id': 'transaction_id',\n",
    "        'customer_name': 'customer',\n",
    "        'product_category': 'category',\n",
    "        'payment_method': 'payment_type'\n",
    "    }, inplace=True)\n",
    "\n",
    "\n",
    "    return df_transformed\n",
    "\n",
    "if not df_full_extraction.empty:\n",
    "    df_transformed_full = transform_sales_data(df_full_extraction)\n",
    "\n",
    "    print(f\"\\nTransformed {len(df_transformed_full)} records from full extraction.\")\n",
    "    print(\"\\nFirst 5 rows of transformed full data:\")\n",
    "    print(df_transformed_full.head())\n",
    "    print(\"\\nData types of transformed full data:\")\n",
    "    print(df_transformed_full.info())\n",
    "\n",
    "    try:\n",
    "        df_transformed_full.to_csv(OUTPUT_FULL_TRANSFORMED_FILENAME, index=False)\n",
    "        print(f\"\\nTransformed full data successfully saved to '{OUTPUT_FULL_TRANSFORMED_FILENAME}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving transformed full data to CSV: {e}\")\n",
    "else:\n",
    "    print(\"Full extraction DataFrame is empty. Skipping full data transformation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3949fd9f",
   "metadata": {},
   "source": [
    "#### Incremental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9594a2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremental extraction DataFrame is empty. Skipping incremental data transformation.\n"
     ]
    }
   ],
   "source": [
    "if not df_incremental_extraction.empty:\n",
    "    df_transformed_incremental = transform_sales_data(df_incremental_extraction)\n",
    "\n",
    "    print(f\"\\nTransformed {len(df_transformed_incremental)} records from incremental extraction.\")\n",
    "    print(\"\\nFirst 5 rows of transformed incremental data:\")\n",
    "    print(df_transformed_incremental.head())\n",
    "    print(\"\\nData types of transformed incremental data:\")\n",
    "    print(df_transformed_incremental.info())\n",
    "\n",
    "    try:\n",
    "        df_transformed_incremental.to_csv(OUTPUT_INCREMENTAL_TRANSFORMED_FILENAME, index=False)\n",
    "        print(f\"\\nTransformed incremental data successfully saved to '{OUTPUT_INCREMENTAL_TRANSFORMED_FILENAME}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving transformed incremental data to CSV: {e}\")\n",
    "else:\n",
    "    print(\"Incremental extraction DataFrame is empty. Skipping incremental data transformation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa5af71",
   "metadata": {},
   "source": [
    "#### Structuring data\n",
    "- Standardizing data formats and types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac006f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_data(df):\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "    df['quantity'] = df['quantity'].astype(int)\n",
    "    df.rename(columns={'unit_price': 'price_per_unit'}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118b812",
   "metadata": {},
   "source": [
    "### Update Last Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c8282a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving New Timestamp ---\n",
      "New extraction timestamp saved: 2025-06-14T10:30:50.574049\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Saving New Timestamp ---\")\n",
    "current_extraction_time = datetime.now()\n",
    "try:\n",
    "    with open(LAST_EXTRACTION_FILE, 'w') as f:\n",
    "        f.write(current_extraction_time.isoformat())\n",
    "    print(f\"New extraction timestamp saved: {current_extraction_time.isoformat()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving new timestamp to '{LAST_EXTRACTION_FILE}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987f023f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d2cbb72",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
