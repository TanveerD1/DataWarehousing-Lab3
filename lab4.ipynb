{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec4a4ab3",
   "metadata": {},
   "source": [
    "# Lab 4\n",
    "# Extend ETL pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d8caf",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32f8509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589143a",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a11cd008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file: custom_data.csv\n"
     ]
    }
   ],
   "source": [
    "DATA_FILE = 'custom_data.csv' # Your existing data file\n",
    "LAST_EXTRACTION_FILE = 'last_extraction.txt'\n",
    "OUTPUT_FULL_TRANSFORMED_FILENAME = 'transformed_full.csv'\n",
    "OUTPUT_INCREMENTAL_TRANSFORMED_FILENAME = 'transformed_incremental.csv'\n",
    "print(f\"Data file: {DATA_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d3626f",
   "metadata": {},
   "source": [
    "#### Full extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eee310c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 338 rows.\n",
      "First 5 rows of full data:\n",
      "    record_id transaction_date transaction_timestamp customer_name  \\\n",
      "0          1       2025-04-01   2025-04-01T17:49:57        Costco   \n",
      "1          2       2025-04-01   2025-04-01T10:36:18         Apple   \n",
      "2          3       2025-04-01   2025-04-01T17:16:47        Target   \n",
      "3          4       2025-04-01   2025-04-01T18:15:48        Costco   \n",
      "4          5       2025-04-01   2025-04-01T02:37:35        Amazon   \n",
      "\n",
      "  product_category   amount  quantity payment_method last_updated_timestamp  \\\n",
      "0      Electronics   929.94         1         PayPal    2025-04-01T18:49:57   \n",
      "1        Groceries   130.17         4         PayPal    2025-04-01T12:59:18   \n",
      "2       Home Goods  1333.76         8    Credit Card    2025-04-01T18:19:47   \n",
      "3            Tools  1115.54         9         PayPal    2025-04-01T20:41:48   \n",
      "4         Software   633.14         6    Credit Card    2025-04-01T03:35:35   \n",
      "\n",
      "      status  \n",
      "0    Pending  \n",
      "1  Cancelled  \n",
      "2    Pending  \n",
      "3  Cancelled  \n",
      "4  Cancelled  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 338 entries, 0 to 337\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   record_id               338 non-null    int64  \n",
      " 1   transaction_date        338 non-null    object \n",
      " 2   transaction_timestamp   338 non-null    object \n",
      " 3   customer_name           338 non-null    object \n",
      " 4   product_category        338 non-null    object \n",
      " 5   amount                  338 non-null    float64\n",
      " 6   quantity                338 non-null    int64  \n",
      " 7   payment_method          338 non-null    object \n",
      " 8   last_updated_timestamp  338 non-null    object \n",
      " 9   status                  338 non-null    object \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 26.5+ KB\n",
      "\n",
      "Data Types:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "full_data_df = pd.DataFrame() \n",
    "\n",
    "try:\n",
    "    if os.path.exists(DATA_FILE):\n",
    "        full_data_df = pd.read_csv(DATA_FILE)\n",
    "        print(f\"Extracted {full_data_df.shape[0]} rows.\")\n",
    "        print(\"First 5 rows of full data:\\n\", full_data_df.head())\n",
    "        print(\"\\nData Types:\\n\", full_data_df.info())\n",
    "    else:\n",
    "        print(f\"Error: '{DATA_FILE}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during full extraction: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec8dea7",
   "metadata": {},
   "source": [
    "### Incremental extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1374a487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last extraction timestamp: 2025-06-14 10:30:50.574049\n",
      "Extracted 0 incremental rows.\n",
      "No new or updated records found.\n"
     ]
    }
   ],
   "source": [
    "def get_last_timestamp(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            timestamp_str = f.read().strip()\n",
    "            if timestamp_str:\n",
    "                return datetime.fromisoformat(timestamp_str)\n",
    "    return datetime.min \n",
    "\n",
    "last_extraction_time = get_last_timestamp(LAST_EXTRACTION_FILE)\n",
    "print(f\"Last extraction timestamp: {last_extraction_time}\")\n",
    "\n",
    "incremental_data_df = pd.DataFrame() \n",
    "\n",
    "try:\n",
    "    if not full_data_df.empty: \n",
    "        full_data_df['last_updated_timestamp'] = pd.to_datetime(full_data_df['last_updated_timestamp'], errors='coerce')\n",
    "        \n",
    "        incremental_data_df = full_data_df[\n",
    "            full_data_df['last_updated_timestamp'] > last_extraction_time\n",
    "        ].copy() \n",
    "\n",
    "        print(f\"Extracted {incremental_data_df.shape[0]} incremental rows.\")\n",
    "        if not incremental_data_df.empty:\n",
    "            print(\"First 5 rows of incremental data:\\n\", incremental_data_df.head())\n",
    "        else:\n",
    "            print(\"No new or updated records found.\")\n",
    "    else:\n",
    "        print(\"No full data to perform incremental extraction from.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during incremental extraction: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ca651",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "- cleaning\n",
    "- standradization\n",
    "- type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cf4946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformations(df):\n",
    "    transformed_df = df.copy()\n",
    "\n",
    "    # Cleaning: Remove duplicates\n",
    "    transformed_df.drop_duplicates(subset=['record_id'], keep='first', inplace=True)\n",
    "\n",
    "    # Cleaning: Strip whitespace from string columns\n",
    "    for col in ['customer_name', 'product_category', 'payment_method', 'status']:\n",
    "        if col in transformed_df.columns and transformed_df[col].dtype == 'object':\n",
    "            transformed_df[col] = transformed_df[col].str.strip()\n",
    "\n",
    "    # Cleaning: Standardize 'status' casing\n",
    "    if 'status' in transformed_df.columns:\n",
    "        transformed_df['status'] = transformed_df['status'].str.title()\n",
    "\n",
    "    # Cleaning: Handle missing values in critical columns\n",
    "    transformed_df.dropna(subset=['amount', 'quantity', 'transaction_date', 'transaction_timestamp'], inplace=True)\n",
    "\n",
    "    # Structural: Data Type Conversion\n",
    "    transformed_df['transaction_date'] = pd.to_datetime(transformed_df['transaction_date'], errors='coerce')\n",
    "    transformed_df['transaction_timestamp'] = pd.to_datetime(transformed_df['transaction_timestamp'], errors='coerce')\n",
    "    transformed_df['last_updated_timestamp'] = pd.to_datetime(transformed_df['last_updated_timestamp'], errors='coerce')\n",
    "    transformed_df['amount'] = pd.to_numeric(transformed_df['amount'], errors='coerce')\n",
    "    transformed_df['quantity'] = pd.to_numeric(transformed_df['quantity'], errors='coerce')\n",
    "\n",
    "    # Enrichment: Calculate total_price\n",
    "    transformed_df['total_price'] = transformed_df['quantity'] * transformed_df['amount']\n",
    "\n",
    "    # Structural: Column Selection and Renaming\n",
    "    selected_cols = [\n",
    "        'record_id',\n",
    "        'transaction_date',\n",
    "        'transaction_timestamp',\n",
    "        'customer_name',\n",
    "        'product_category',\n",
    "        'quantity',\n",
    "        'amount',\n",
    "        'total_price',\n",
    "        'payment_method',\n",
    "        'status'\n",
    "    ]\n",
    "    transformed_df = transformed_df[[col for col in selected_cols if col in transformed_df.columns]]\n",
    "\n",
    "    transformed_df.rename(columns={\n",
    "        'record_id': 'transaction_id',\n",
    "        'customer_name': 'customer',\n",
    "        'product_category': 'category',\n",
    "        'payment_method': 'payment_type'\n",
    "    }, inplace=True)\n",
    "\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3949fd9f",
   "metadata": {},
   "source": [
    "#### Transform full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9594a2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Transforming Full Data ---\n",
      "Transformed 338 records for full data.\n",
      "First 5 rows of transformed full data:\n",
      "    transaction_id transaction_date transaction_timestamp customer  \\\n",
      "0               1       2025-04-01   2025-04-01 17:49:57   Costco   \n",
      "1               2       2025-04-01   2025-04-01 10:36:18    Apple   \n",
      "2               3       2025-04-01   2025-04-01 17:16:47   Target   \n",
      "3               4       2025-04-01   2025-04-01 18:15:48   Costco   \n",
      "4               5       2025-04-01   2025-04-01 02:37:35   Amazon   \n",
      "\n",
      "      category  quantity   amount  total_price payment_type     status  \n",
      "0  Electronics         1   929.94       929.94       PayPal    Pending  \n",
      "1    Groceries         4   130.17       520.68       PayPal  Cancelled  \n",
      "2   Home Goods         8  1333.76     10670.08  Credit Card    Pending  \n",
      "3        Tools         9  1115.54     10039.86       PayPal  Cancelled  \n",
      "4     Software         6   633.14      3798.84  Credit Card  Cancelled  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 338 entries, 0 to 337\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   transaction_id         338 non-null    int64         \n",
      " 1   transaction_date       338 non-null    datetime64[ns]\n",
      " 2   transaction_timestamp  338 non-null    datetime64[ns]\n",
      " 3   customer               338 non-null    object        \n",
      " 4   category               338 non-null    object        \n",
      " 5   quantity               338 non-null    int64         \n",
      " 6   amount                 338 non-null    float64       \n",
      " 7   total_price            338 non-null    float64       \n",
      " 8   payment_type           338 non-null    object        \n",
      " 9   status                 338 non-null    object        \n",
      "dtypes: datetime64[ns](2), float64(2), int64(2), object(4)\n",
      "memory usage: 29.0+ KB\n",
      "\n",
      "Data Types:\n",
      " None\n",
      "Transformed full data saved to 'transformed_full.csv'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Transforming Full Data ---\")\n",
    "if not full_data_df.empty:\n",
    "    transformed_full_df = apply_transformations(full_data_df)\n",
    "    print(f\"Transformed {len(transformed_full_df)} records for full data.\")\n",
    "    print(\"First 5 rows of transformed full data:\\n\", transformed_full_df.head())\n",
    "    print(\"\\nData Types:\\n\", transformed_full_df.info())\n",
    "\n",
    "    try:\n",
    "        transformed_full_df.to_csv(OUTPUT_FULL_TRANSFORMED_FILENAME, index=False)\n",
    "        print(f\"Transformed full data saved to '{OUTPUT_FULL_TRANSFORMED_FILENAME}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving transformed full data: {e}\")\n",
    "else:\n",
    "    print(\"Full data is empty, skipping transformation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f208d344",
   "metadata": {},
   "source": [
    "#### Incremental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e49ccb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremental data is empty, skipping transformation.\n"
     ]
    }
   ],
   "source": [
    "if not incremental_data_df.empty:\n",
    "    transformed_incremental_df = apply_transformations(incremental_data_df)\n",
    "    print(f\"Transformed {len(transformed_incremental_df)} records for incremental data.\")\n",
    "    print(\"First 5 rows of transformed incremental data:\\n\", transformed_incremental_df.head())\n",
    "    print(\"\\nData Types:\\n\", transformed_incremental_df.info())\n",
    "\n",
    "    try:\n",
    "        transformed_incremental_df.to_csv(OUTPUT_INCREMENTAL_TRANSFORMED_FILENAME, index=False)\n",
    "        print(f\"Transformed incremental data saved to '{OUTPUT_INCREMENTAL_TRANSFORMED_FILENAME}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving transformed incremental data: {e}\")\n",
    "else:\n",
    "    print(\"Incremental data is empty, skipping transformation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118b812",
   "metadata": {},
   "source": [
    "### Update Last Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c8282a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving New Timestamp ---\n",
      "New extraction timestamp saved: 2025-06-14T10:30:50.574049\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Saving New Timestamp ---\")\n",
    "current_extraction_time = datetime.now()\n",
    "try:\n",
    "    with open(LAST_EXTRACTION_FILE, 'w') as f:\n",
    "        f.write(current_extraction_time.isoformat())\n",
    "    print(f\"New extraction timestamp saved: {current_extraction_time.isoformat()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving new timestamp to '{LAST_EXTRACTION_FILE}': {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
